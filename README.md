# Strategizing Against Q-Learners: A Control-Theoretical Approach

This repository contains MATLAB code accompanying the letter:

> **Y. ArslantaÅŸ, E. YÃ¼ceel, and M. O. Sayin**,  
> *Strategizing Against Q-Learners: A Control-Theoretical Approach*,  
> IEEE Control Systems Letters, vol. 8, pp. 1733â€“1738, 2024.  
> [DOI: 10.1109/LCSYS.2024.3416240](https://doi.org/10.1109/LCSYS.2024.3416240)

---

## ğŸ“– Overview

Independent Q-learning (IQL) is a widely used multi-agent reinforcement learning algorithm. However, it can be vulnerable to **strategically sophisticated opponents** who know the learning dynamics.

This project provides a MATLAB implementation of the control-theoretical approach proposed in the paper, where:

- **Naive agents (Q-learners)** update their Q-values using softmax exploration.  
- **Strategic agents (DP-based)** treat the Q-learnersâ€™ dynamics as a controlled system and compute optimal strategies via **quantization-based dynamic programming**.  

The simulations include:

- **Q vs Q**: Two Q-learners playing against each other.  
- **Q vs DP**: A Q-learner against a dynamic-programming-based strategic agent.  
- Comparison of **empirical frequency profiles** and **discounted payoffs**.  

---

## ğŸ“‚ Repository Structure

- `main.m` â€“ Entry point for running simulations (selects game, sets parameters, runs experiments).  
- `getGame.m` â€“ Utility for loading payoff matrices (e.g., Prisonerâ€™s Dilemma).  
- `QvsQ.m` â€“ Simulation of two Q-learners interacting.  
- `QvsDP.m` â€“ Simulation of Q-learner vs. strategic agent.  
- `runDP.m` â€“ Backward induction for computing DP-based optimal policy.  
- `chooseAction.m` â€“ Helper function for sampling actions given a probability distribution.  
- `quantizer.m`, `inverse_quantizer.m` â€“ State quantization utilities.  

---

## âš™ï¸ Usage

### 1. Clone the repository
```bash
git clone https://github.com/yukselarslantas/ewa-vs-dp.git
cd ewa-vs-dp
```
### 2. Run in MATLAB

### 3. Results

Plots will show:

- The evolution of empirical frequencies (**CC, CD, DC, DD**)  
- Comparison of **Q vs Q** and **Q vs DP** interactions  
- Computed **discounted payoffs**  

Results are automatically saved in `.mat` files depending on the selected game type.

## ğŸ® Example

In `main.m`, select the game type:

```matlab
[UA, UB, saveFile] = getGame('pd'); % Prisonerâ€™s Dilemma

Adjust learning and DP parameters:

params.alpha = 0.1;   % learning rate
params.gamma = 0.8;   % discount factor
params.tau   = 0.01;  % softmax temperature
params.H     = 20;    % DP horizon


## ğŸ“‘ Reference
If you use this code, please cite:

```bibtex
@article{arslantas2024strategizing,
  title={Strategizing Against Q-Learners: A Control-Theoretical Approach},
  author={Arslantas, Yuksel and Yuceel, Ege and Sayin, Muhammed O.},
  journal={IEEE Control Systems Letters},
  volume={8},
  pages={1733--1738},
  year={2024},
  publisher={IEEE}
}